{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 1: Platform Classification using Supervised Learning Methods - Building Training and Test datasets (part 2 b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "* https://www.quora.com/What-is-the-best-way-to-create-a-training-set-for-machine-learning/answer/Clem-Wang-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, pathlib\n",
    "from IPython.display import display, Math, Latex #also '%%latex' magic command\n",
    "import collections, itertools, operator, re, copy, datetime\n",
    "import urllib, urllib.request, urllib.parse, dns, ipwhois\n",
    "import pickle, json, csv, zipfile\n",
    "import math, random, numpy, scipy, pandas\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import bs4\n",
    "import nltk, sklearn\n",
    "\n",
    "#actualcwd = os.getcwd()\n",
    "#os.chdir(actualcwd)\n",
    "#print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "#a simple but not adequate hack to solve:\n",
    "#-- that this notebook will include any passed module that exists on top of its folder\n",
    "#-- that my installation of the the nltk will find the correct path to the nlkt_data folder\n",
    "#\n",
    "#once this line is run, IT SHOULDN'T RUN AGAIN!, otherwise the cwd will change into something different; \n",
    "#it can restored though in different ways, one by using `actualcwd` variable or in some cases shuting down this notebook\n",
    "#\n",
    "#\n",
    "os.chdir('../..')\n",
    "#print(os.getcwd())\n",
    "sys.path.append(os.getcwd())\n",
    "import config.config as config\n",
    "\n",
    "#print(config.anacondadir)\n",
    "\n",
    "if os.path.exists(config.anacondadir):\n",
    "    print('ok')\n",
    "    nltk.data.path.append(config.anacondadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-bfc7f4b2e6e8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-bfc7f4b2e6e8>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    STOP HERE!!\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "STOP HERE!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#OBSERVATION!: name of file has been changed to reflect last updated file \n",
    "if pathlib.Path(os.getcwd()+'/data/annotatedplatformsphase1_a2.csv').is_file():\n",
    "    pd_annotated = pandas.read_csv(open(os.getcwd()+'/data/annotatedplatformsphase1_a2.csv', 'r'), sep=';', quotechar=\"'\")\n",
    "else:\n",
    "    print('Not path found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>alltext</th>\n",
       "      <th>category</th>\n",
       "      <th>category_regex</th>\n",
       "      <th>description</th>\n",
       "      <th>htext</th>\n",
       "      <th>keywords</th>\n",
       "      <th>params</th>\n",
       "      <th>platform</th>\n",
       "      <th>title</th>\n",
       "      <th>wiki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>components clearfix world carousel buttons h...</td>\n",
       "      <td>PACKAGE</td>\n",
       "      <td>api|package|framework|librar|stack|licens|addo...</td>\n",
       "      <td>the most popular html, css, and js framework i...</td>\n",
       "      <td>Bootstrap is the most popular HTML, CSS, and J...</td>\n",
       "      <td></td>\n",
       "      <td>,/components,/components/breadcrumb/,/migratio...</td>\n",
       "      <td>v4-alpha.getbootstrap.com</td>\n",
       "      <td>\\n  \\n    bootstrap · the most popular html, c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>plugin loaded github new com iscroll cubiq e...</td>\n",
       "      <td>PACKAGE</td>\n",
       "      <td>api|package|framework|librar|stack|licens|addo...</td>\n",
       "      <td></td>\n",
       "      <td>jScroll is a jQuery plugin for infinite scroll...</td>\n",
       "      <td></td>\n",
       "      <td>/,https://github.com/cubiq/iscroll</td>\n",
       "      <td>jscroll.com</td>\n",
       "      <td>jscroll - a jquery plugin for infinite scrolli...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>validation mongoose models node queries api ...</td>\n",
       "      <td>PACKAGE</td>\n",
       "      <td>api|package|framework|librar|stack|licens|addo...</td>\n",
       "      <td></td>\n",
       "      <td>Elegant MongoDB object modeling for Node.js Mo...</td>\n",
       "      <td></td>\n",
       "      <td>/docs/promises.html,/docs/populate.html,/docs/...</td>\n",
       "      <td>mongoosejs.com</td>\n",
       "      <td>mongoose odm v4.10.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>charts samples jsonp navigator view highchar...</td>\n",
       "      <td>PACKAGE</td>\n",
       "      <td>api|package|framework|librar|stack|licens|addo...</td>\n",
       "      <td>Highcharts - Interactive JavaScript charts for...</td>\n",
       "      <td>View demo Get a license</td>\n",
       "      <td>highcharts, charts, javascript charts, ajax ch...</td>\n",
       "      <td>/samples/data/jsonp.php,/blog/192-use-highchar...</td>\n",
       "      <td>www.highcharts.com</td>\n",
       "      <td>Interactive JavaScript charts for your webpage...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>crossorigin org wikipedia api w free https e...</td>\n",
       "      <td>PACKAGE</td>\n",
       "      <td>api|package|framework|librar|stack|licens|addo...</td>\n",
       "      <td></td>\n",
       "      <td>\\n                  Welcome to crossorigin.me,...</td>\n",
       "      <td></td>\n",
       "      <td>/https://en.wikipedia.org/w/api.php,/,/https:/...</td>\n",
       "      <td>www.crossorigin.me</td>\n",
       "      <td>crossorigin.me</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1  \\\n",
       "0           0             0             0   \n",
       "1           1             3             3   \n",
       "2           2            10            10   \n",
       "3           3            34            34   \n",
       "4           4            41            41   \n",
       "\n",
       "                                             alltext category  \\\n",
       "0    components clearfix world carousel buttons h...  PACKAGE   \n",
       "1    plugin loaded github new com iscroll cubiq e...  PACKAGE   \n",
       "2    validation mongoose models node queries api ...  PACKAGE   \n",
       "3    charts samples jsonp navigator view highchar...  PACKAGE   \n",
       "4    crossorigin org wikipedia api w free https e...  PACKAGE   \n",
       "\n",
       "                                      category_regex  \\\n",
       "0  api|package|framework|librar|stack|licens|addo...   \n",
       "1  api|package|framework|librar|stack|licens|addo...   \n",
       "2  api|package|framework|librar|stack|licens|addo...   \n",
       "3  api|package|framework|librar|stack|licens|addo...   \n",
       "4  api|package|framework|librar|stack|licens|addo...   \n",
       "\n",
       "                                         description  \\\n",
       "0  the most popular html, css, and js framework i...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  Highcharts - Interactive JavaScript charts for...   \n",
       "4                                                      \n",
       "\n",
       "                                               htext  \\\n",
       "0  Bootstrap is the most popular HTML, CSS, and J...   \n",
       "1  jScroll is a jQuery plugin for infinite scroll...   \n",
       "2  Elegant MongoDB object modeling for Node.js Mo...   \n",
       "3                           View demo Get a license    \n",
       "4  \\n                  Welcome to crossorigin.me,...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  highcharts, charts, javascript charts, ajax ch...   \n",
       "4                                                      \n",
       "\n",
       "                                              params  \\\n",
       "0  ,/components,/components/breadcrumb/,/migratio...   \n",
       "1                 /,https://github.com/cubiq/iscroll   \n",
       "2  /docs/promises.html,/docs/populate.html,/docs/...   \n",
       "3  /samples/data/jsonp.php,/blog/192-use-highchar...   \n",
       "4  /https://en.wikipedia.org/w/api.php,/,/https:/...   \n",
       "\n",
       "                    platform  \\\n",
       "0  v4-alpha.getbootstrap.com   \n",
       "1                jscroll.com   \n",
       "2             mongoosejs.com   \n",
       "3         www.highcharts.com   \n",
       "4         www.crossorigin.me   \n",
       "\n",
       "                                               title wiki  \n",
       "0  \\n  \\n    bootstrap · the most popular html, c...  NaN  \n",
       "1  jscroll - a jquery plugin for infinite scrolli...  NaN  \n",
       "2                               mongoose odm v4.10.5  NaN  \n",
       "3  Interactive JavaScript charts for your webpage...  NaN  \n",
       "4                                     crossorigin.me  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_annotated.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OBSERVATION!: name of file has been changed to reflect last updated file \n",
    "if pathlib.Path(os.getcwd()+'/data/notatedplatformsphase1_a2.csv').is_file():\n",
    "    pd_notated = pandas.read_csv(open(os.getcwd()+'/data/notatedplatformsphase1_a2.csv', 'r'), sep=';', quotechar=\"'\")\n",
    "else:\n",
    "    print('Not path found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>platform</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "      <th>htext</th>\n",
       "      <th>params</th>\n",
       "      <th>category</th>\n",
       "      <th>wiki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>svenv.nl</td>\n",
       "      <td>\\n\\n            \\n                Home\\n      ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Nowadays, many webpages are being styled using...</td>\n",
       "      <td>/programming/whyihatebootstrap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>envato.com</td>\n",
       "      <td>Envato - Top digital assets and services</td>\n",
       "      <td>Join millions &amp; bring your ideas and projects ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>/blog/css3-flexbox/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Envato (formerly Eden) operates a group of dig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>naimhamadi.wordpress.com</td>\n",
       "      <td>Naim Hammadi's Blog</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Naim Hammadi's Blog</td>\n",
       "      <td>/2014/05/13/mastering-css-selectors/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WordPress.com is a blog web hosting service pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>www.fusioncharts.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>/blog/2013/12/jsdoc-vs-yuidoc-vs-doxx-vs-docco...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FusionCharts, part of InfoSoft Global (P) Ltd,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>lh3.googleusercontent.com</td>\n",
       "      <td>Error 404 (Not Found)!!1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>404. That’s an error.\\n</td>\n",
       "      <td>/MewY8qm8NVCQ3YcSuy92f8sUP18qUfKIQkUJhLq46otOj...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   platform  \\\n",
       "0           0                   svenv.nl   \n",
       "1           1                 envato.com   \n",
       "2           2   naimhamadi.wordpress.com   \n",
       "3           3       www.fusioncharts.com   \n",
       "4           4  lh3.googleusercontent.com   \n",
       "\n",
       "                                               title  \\\n",
       "0  \\n\\n            \\n                Home\\n      ...   \n",
       "1           Envato - Top digital assets and services   \n",
       "2                                Naim Hammadi's Blog   \n",
       "3                                                      \n",
       "4                           Error 404 (Not Found)!!1   \n",
       "\n",
       "                                         description keywords  \\\n",
       "0                                                NaN            \n",
       "1  Join millions & bring your ideas and projects ...            \n",
       "2                                                               \n",
       "3                                                               \n",
       "4                                                               \n",
       "\n",
       "                                               htext  \\\n",
       "0  Nowadays, many webpages are being styled using...   \n",
       "1                                                      \n",
       "2                              Naim Hammadi's Blog     \n",
       "3                                                      \n",
       "4                           404. That’s an error.\\n    \n",
       "\n",
       "                                              params  category  \\\n",
       "0                     /programming/whyihatebootstrap       NaN   \n",
       "1                                /blog/css3-flexbox/       NaN   \n",
       "2               /2014/05/13/mastering-css-selectors/       NaN   \n",
       "3  /blog/2013/12/jsdoc-vs-yuidoc-vs-doxx-vs-docco...       NaN   \n",
       "4  /MewY8qm8NVCQ3YcSuy92f8sUP18qUfKIQkUJhLq46otOj...       NaN   \n",
       "\n",
       "                                                wiki  \n",
       "0                                                NaN  \n",
       "1  Envato (formerly Eden) operates a group of dig...  \n",
       "2  WordPress.com is a blog web hosting service pr...  \n",
       "3  FusionCharts, part of InfoSoft Global (P) Ltd,...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_notated.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA UPDATING - Important..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code commented below was used to:\n",
    "* **Add wikipedia info to the created tables**: for this I used the `scr.wikipedia_extract` module made for this purpose\n",
    "* **Revise some column naming and use the names for categories** to be used from now on: until now (29-July-17), I was using as categories a regex form I used for the original classification rules; from now I will be using the defined categories found in the `docs` folder of this work\n",
    "\n",
    "The changes below were done by creating updated files, re-opening that file and update it until the right file was created. Once the information was updated with some information, the respective code was commented because it was not of usage any more.\n",
    "\n",
    "The code below is kept commented but is shown so other users of this file can have a reference. Also the different intermediate files are kept in the `data` folder but only the required files are called for further analysis. In a more advanced phase a simpler file will be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import scr.wikipedia_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#imp.reload(scr.wikipedia_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd_annotated['wiki'] = ''\n",
    "#pd_notated['wiki'] = ''\n",
    "#scr.wikipedia_extract.getting_wikipedia(pd_annotated)\n",
    "#scr.wikipedia_extract.getting_wikipedia(pd_notated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd_errortemp = pd_notated.loc[pd_notated['platform'] == 'view-source:http:',]\n",
    "#scr.wikipedia_extract.getting_wikipedia(pd_errortemp)\n",
    "#print(pd_errortemp)\n",
    "#print(pd_notated.iloc[110,])\n",
    "#url = 'https://en.wikipedia.org/w/api.php?action=query&list=search&format=json&srsearch=JavaScript Objects in Detail'\n",
    "#req = urllib.request.Request(url)\n",
    "#try:\n",
    "#    resp = urllib.request.urlopen(req)\n",
    "#except urllib.error.HTTPError as e:\n",
    "#    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd_notated.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd_annotated = pd_annotated.rename(columns={'category':'category_regex'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd_annotated.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#categories = pandas.read_csv(open(os.getcwd()+'/docs/category_operationalization.csv', 'r'), sep=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#categories = categories[['category','category_regex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd_annotated = pandas.merge(pd_annotated, categories, on=['category_regex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd_annotated.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd_annotated.to_csv(os.getcwd()+'/data/annotatedplatformsphase1_a1.csv', sep=';', quotechar=\"'\")\n",
    "#pd_notated.to_csv(os.getcwd()+'/data/notatedplatformsphase1_a2.csv', sep=';', quotechar=\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STOP HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import scr.datapreparation_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#imp.reload(scr.datapreparation_ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0  has the following null values:  Unnamed: 0    0\n",
      "dtype: int64\n",
      "Unnamed: 0.1  has the following null values:  Unnamed: 0.1    0\n",
      "Unnamed: 0.1    0\n",
      "dtype: int64\n",
      "Unnamed: 0.1  has the following null values:  Unnamed: 0.1    0\n",
      "Unnamed: 0.1    0\n",
      "dtype: int64\n",
      "alltext  has the following null values:  alltext    0\n",
      "dtype: int64\n",
      "category  has the following null values:  category    0\n",
      "dtype: int64\n",
      "category_regex  has the following null values:  category_regex    323\n",
      "dtype: int64\n",
      "description  has the following null values:  description    20\n",
      "dtype: int64\n",
      "htext  has the following null values:  htext    0\n",
      "dtype: int64\n",
      "keywords  has the following null values:  keywords    5\n",
      "dtype: int64\n",
      "params  has the following null values:  params    19\n",
      "dtype: int64\n",
      "platform  has the following null values:  platform    0\n",
      "dtype: int64\n",
      "title  has the following null values:  title    3\n",
      "dtype: int64\n",
      "wiki  has the following null values:  wiki    643\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in pd_annotated.columns:\n",
    "    print(col,' has the following null values: ', pd_annotated[[col]].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(773, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_annotated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0  has the following null values:  Unnamed: 0    0\n",
      "dtype: int64\n",
      "platform  has the following null values:  platform    0\n",
      "dtype: int64\n",
      "title  has the following null values:  title    0\n",
      "dtype: int64\n",
      "description  has the following null values:  description    3\n",
      "dtype: int64\n",
      "keywords  has the following null values:  keywords    2\n",
      "dtype: int64\n",
      "htext  has the following null values:  htext    0\n",
      "dtype: int64\n",
      "params  has the following null values:  params    7\n",
      "dtype: int64\n",
      "category  has the following null values:  category    258\n",
      "dtype: int64\n",
      "wiki  has the following null values:  wiki    210\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in pd_notated.columns:\n",
    "    print(col,' has the following null values: ', pd_notated[[col]].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_notated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pd_annotated['alltext'] = ''\n",
    "#scr.datapreparation_ML.datapreparation(pd_annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_notated['alltext'] = ''\n",
    "scr.datapreparation_ML.datapreparation(pd_notated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jscheck(x):\n",
    "    plat = x\n",
    "    if len(plat.split('.')) > 1:\n",
    "        if len(plat.split('.')[-2]) > 5:\n",
    "            if plat.split('.')[-2][-2:] == 'js':\n",
    "                return 1\n",
    "        elif plat.split('.')[0] == 'api':\n",
    "            return 1\n",
    "    \n",
    "    return 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def docscheck(x):\n",
    "    plat = x\n",
    "    if len(plat.split('.')) > 1:\n",
    "        if len(plat.split('.')[0]) > 2:\n",
    "            if plat.split('.')[0] in ['docs', 'dev', 'developers', 'developer']:\n",
    "                return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blogscheck(x):\n",
    "    plat = x\n",
    "    if len(plat.split('.')) > 1:\n",
    "        if len(plat.split('.')[0]) > 2:\n",
    "            if plat.split('.')[0] in ['blog', 'blogs', 'articule', 'articules']:\n",
    "                return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def commcheck(x):\n",
    "    plat = x\n",
    "    if len(plat.split('.')) > 1:\n",
    "        if len(plat.split('.')[0]) > 2:\n",
    "            if plat.split('.')[0] in ['forum', 'forums', 'community', 'channel']:\n",
    "                return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_annotated['jscheck'] = None\n",
    "pd_annotated['docscheck'] = None\n",
    "pd_annotated['blogscheck'] = None\n",
    "pd_annotated['commcheck'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd_annotated['jscheck'] = pd_annotated['platform'].apply(jscheck)\n",
    "pd_annotated['docscheck'] = pd_annotated['platform'].apply(docscheck)\n",
    "pd_annotated['blogscheck'] = pd_annotated['platform'].apply(blogscheck)\n",
    "pd_annotated['commcheck'] = pd_annotated['platform'].apply(commcheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>alltext</th>\n",
       "      <th>category</th>\n",
       "      <th>category_regex</th>\n",
       "      <th>description</th>\n",
       "      <th>htext</th>\n",
       "      <th>keywords</th>\n",
       "      <th>params</th>\n",
       "      <th>platform</th>\n",
       "      <th>title</th>\n",
       "      <th>wiki</th>\n",
       "      <th>jscheck</th>\n",
       "      <th>docscheck</th>\n",
       "      <th>blogscheck</th>\n",
       "      <th>commcheck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>components clearfix world carousel buttons h...</td>\n",
       "      <td>PACKAGE</td>\n",
       "      <td>api|package|framework|librar|stack|licens|addo...</td>\n",
       "      <td>the most popular html, css, and js framework i...</td>\n",
       "      <td>Bootstrap is the most popular HTML, CSS, and J...</td>\n",
       "      <td></td>\n",
       "      <td>,/components,/components/breadcrumb/,/migratio...</td>\n",
       "      <td>v4-alpha.getbootstrap.com</td>\n",
       "      <td>\\n  \\n    bootstrap · the most popular html, c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>plugin loaded github new com iscroll cubiq e...</td>\n",
       "      <td>PACKAGE</td>\n",
       "      <td>api|package|framework|librar|stack|licens|addo...</td>\n",
       "      <td></td>\n",
       "      <td>jScroll is a jQuery plugin for infinite scroll...</td>\n",
       "      <td></td>\n",
       "      <td>/,https://github.com/cubiq/iscroll</td>\n",
       "      <td>jscroll.com</td>\n",
       "      <td>jscroll - a jquery plugin for infinite scrolli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>validation mongoose models node queries api ...</td>\n",
       "      <td>PACKAGE</td>\n",
       "      <td>api|package|framework|librar|stack|licens|addo...</td>\n",
       "      <td></td>\n",
       "      <td>Elegant MongoDB object modeling for Node.js Mo...</td>\n",
       "      <td></td>\n",
       "      <td>/docs/promises.html,/docs/populate.html,/docs/...</td>\n",
       "      <td>mongoosejs.com</td>\n",
       "      <td>mongoose odm v4.10.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>charts samples jsonp navigator view highchar...</td>\n",
       "      <td>PACKAGE</td>\n",
       "      <td>api|package|framework|librar|stack|licens|addo...</td>\n",
       "      <td>Highcharts - Interactive JavaScript charts for...</td>\n",
       "      <td>View demo Get a license</td>\n",
       "      <td>highcharts, charts, javascript charts, ajax ch...</td>\n",
       "      <td>/samples/data/jsonp.php,/blog/192-use-highchar...</td>\n",
       "      <td>www.highcharts.com</td>\n",
       "      <td>Interactive JavaScript charts for your webpage...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>crossorigin org wikipedia api w free https e...</td>\n",
       "      <td>PACKAGE</td>\n",
       "      <td>api|package|framework|librar|stack|licens|addo...</td>\n",
       "      <td></td>\n",
       "      <td>\\n                  Welcome to crossorigin.me,...</td>\n",
       "      <td></td>\n",
       "      <td>/https://en.wikipedia.org/w/api.php,/,/https:/...</td>\n",
       "      <td>www.crossorigin.me</td>\n",
       "      <td>crossorigin.me</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1  \\\n",
       "0           0             0             0   \n",
       "1           1             3             3   \n",
       "2           2            10            10   \n",
       "3           3            34            34   \n",
       "4           4            41            41   \n",
       "\n",
       "                                             alltext category  \\\n",
       "0    components clearfix world carousel buttons h...  PACKAGE   \n",
       "1    plugin loaded github new com iscroll cubiq e...  PACKAGE   \n",
       "2    validation mongoose models node queries api ...  PACKAGE   \n",
       "3    charts samples jsonp navigator view highchar...  PACKAGE   \n",
       "4    crossorigin org wikipedia api w free https e...  PACKAGE   \n",
       "\n",
       "                                      category_regex  \\\n",
       "0  api|package|framework|librar|stack|licens|addo...   \n",
       "1  api|package|framework|librar|stack|licens|addo...   \n",
       "2  api|package|framework|librar|stack|licens|addo...   \n",
       "3  api|package|framework|librar|stack|licens|addo...   \n",
       "4  api|package|framework|librar|stack|licens|addo...   \n",
       "\n",
       "                                         description  \\\n",
       "0  the most popular html, css, and js framework i...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  Highcharts - Interactive JavaScript charts for...   \n",
       "4                                                      \n",
       "\n",
       "                                               htext  \\\n",
       "0  Bootstrap is the most popular HTML, CSS, and J...   \n",
       "1  jScroll is a jQuery plugin for infinite scroll...   \n",
       "2  Elegant MongoDB object modeling for Node.js Mo...   \n",
       "3                           View demo Get a license    \n",
       "4  \\n                  Welcome to crossorigin.me,...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  highcharts, charts, javascript charts, ajax ch...   \n",
       "4                                                      \n",
       "\n",
       "                                              params  \\\n",
       "0  ,/components,/components/breadcrumb/,/migratio...   \n",
       "1                 /,https://github.com/cubiq/iscroll   \n",
       "2  /docs/promises.html,/docs/populate.html,/docs/...   \n",
       "3  /samples/data/jsonp.php,/blog/192-use-highchar...   \n",
       "4  /https://en.wikipedia.org/w/api.php,/,/https:/...   \n",
       "\n",
       "                    platform  \\\n",
       "0  v4-alpha.getbootstrap.com   \n",
       "1                jscroll.com   \n",
       "2             mongoosejs.com   \n",
       "3         www.highcharts.com   \n",
       "4         www.crossorigin.me   \n",
       "\n",
       "                                               title wiki  jscheck  docscheck  \\\n",
       "0  \\n  \\n    bootstrap · the most popular html, c...  NaN        0          0   \n",
       "1  jscroll - a jquery plugin for infinite scrolli...  NaN        0          0   \n",
       "2                               mongoose odm v4.10.5  NaN        1          0   \n",
       "3  Interactive JavaScript charts for your webpage...  NaN        0          0   \n",
       "4                                     crossorigin.me  NaN        0          0   \n",
       "\n",
       "   blogscheck  commcheck  \n",
       "0           0          0  \n",
       "1           0          0  \n",
       "2           0          0  \n",
       "3           0          0  \n",
       "4           0          0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_notated['jscheck'] = None\n",
    "pd_notated['docscheck'] = None\n",
    "pd_notated['blogscheck'] = None\n",
    "pd_notated['commcheck'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_notated['jscheck'] = pd_notated['platform'].apply(jscheck)\n",
    "pd_notated['docscheck'] = pd_notated['platform'].apply(docscheck)\n",
    "pd_notated['blogscheck'] = pd_notated['platform'].apply(blogscheck)\n",
    "pd_notated['commcheck'] = pd_notated['platform'].apply(commcheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>platform</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "      <th>htext</th>\n",
       "      <th>params</th>\n",
       "      <th>category</th>\n",
       "      <th>wiki</th>\n",
       "      <th>alltext</th>\n",
       "      <th>jscheck</th>\n",
       "      <th>docscheck</th>\n",
       "      <th>blogscheck</th>\n",
       "      <th>commcheck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>svenv.nl</td>\n",
       "      <td>\\n\\n            \\n                Home\\n      ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Nowadays, many webpages are being styled using...</td>\n",
       "      <td>/programming/whyihatebootstrap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>also nl framework think even us less result ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>envato.com</td>\n",
       "      <td>Envato - Top digital assets and services</td>\n",
       "      <td>Join millions &amp; bring your ideas and projects ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>/blog/css3-flexbox/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Envato (formerly Eden) operates a group of dig...</td>\n",
       "      <td>envato creative flexbox ideas top world serv...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>naimhamadi.wordpress.com</td>\n",
       "      <td>Naim Hammadi's Blog</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Naim Hammadi's Blog</td>\n",
       "      <td>/2014/05/13/mastering-css-selectors/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WordPress.com is a blog web hosting service pr...</td>\n",
       "      <td>naim hammadi selectors blog css mastering</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>www.fusioncharts.com</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>/blog/2013/12/jsdoc-vs-yuidoc-vs-doxx-vs-docco...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FusionCharts, part of InfoSoft Global (P) Ltd,...</td>\n",
       "      <td>doxx generator jsdoc vs blog yuidoc choosing...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>lh3.googleusercontent.com</td>\n",
       "      <td>Error 404 (Not Found)!!1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>404. That’s an error.\\n</td>\n",
       "      <td>/MewY8qm8NVCQ3YcSuy92f8sUP18qUfKIQkUJhLq46otOj...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rw error h1080 found mewy8qm8nvcq3ycsuy92f8s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   platform  \\\n",
       "0           0                   svenv.nl   \n",
       "1           1                 envato.com   \n",
       "2           2   naimhamadi.wordpress.com   \n",
       "3           3       www.fusioncharts.com   \n",
       "4           4  lh3.googleusercontent.com   \n",
       "\n",
       "                                               title  \\\n",
       "0  \\n\\n            \\n                Home\\n      ...   \n",
       "1           Envato - Top digital assets and services   \n",
       "2                                Naim Hammadi's Blog   \n",
       "3                                                      \n",
       "4                           Error 404 (Not Found)!!1   \n",
       "\n",
       "                                         description keywords  \\\n",
       "0                                                NaN            \n",
       "1  Join millions & bring your ideas and projects ...            \n",
       "2                                                               \n",
       "3                                                               \n",
       "4                                                               \n",
       "\n",
       "                                               htext  \\\n",
       "0  Nowadays, many webpages are being styled using...   \n",
       "1                                                      \n",
       "2                              Naim Hammadi's Blog     \n",
       "3                                                      \n",
       "4                           404. That’s an error.\\n    \n",
       "\n",
       "                                              params  category  \\\n",
       "0                     /programming/whyihatebootstrap       NaN   \n",
       "1                                /blog/css3-flexbox/       NaN   \n",
       "2               /2014/05/13/mastering-css-selectors/       NaN   \n",
       "3  /blog/2013/12/jsdoc-vs-yuidoc-vs-doxx-vs-docco...       NaN   \n",
       "4  /MewY8qm8NVCQ3YcSuy92f8sUP18qUfKIQkUJhLq46otOj...       NaN   \n",
       "\n",
       "                                                wiki  \\\n",
       "0                                                NaN   \n",
       "1  Envato (formerly Eden) operates a group of dig...   \n",
       "2  WordPress.com is a blog web hosting service pr...   \n",
       "3  FusionCharts, part of InfoSoft Global (P) Ltd,...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                             alltext  jscheck  docscheck  \\\n",
       "0    also nl framework think even us less result ...        0          0   \n",
       "1    envato creative flexbox ideas top world serv...        0          0   \n",
       "2          naim hammadi selectors blog css mastering        0          0   \n",
       "3    doxx generator jsdoc vs blog yuidoc choosing...        0          0   \n",
       "4    rw error h1080 found mewy8qm8nvcq3ycsuy92f8s...        0          0   \n",
       "\n",
       "   blogscheck  commcheck  \n",
       "0           0          0  \n",
       "1           0          0  \n",
       "2           0          0  \n",
       "3           0          0  \n",
       "4           0          0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_notated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-d5af98942240>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-26-d5af98942240>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    STOP HERE!\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "STOP HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def vectorizer(documents):\n",
    "    countvect = CountVectorizer(ngram_range=(1,2))\n",
    "    X_counts = countvect.fit_transform(documents)\n",
    "    return X_counts, countvect\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "import copy\n",
    "def hstacker(X, hackedcolumns):\n",
    "    X_countsh = hstack((copy.copy(X), hackedcolumns))\n",
    "    return X_countsh\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def modelling(Classifier, X, y, params):\n",
    "    #clf_dtm = DecisionTreeClassifier(max_depth=1, min_samples_leaf=1, random_state=0)\n",
    "    clf_dtm = Classifier().set_params(**params)\n",
    "    return clf_dtm, clf_dtm.fit(X, y)\n",
    "\n",
    "def compareyvsypredict(target, y, y_predict):\n",
    "    print('{0:35} => {1:15} => {2:15}'.format('Target','Class','PredClass'))\n",
    "    for plat, category in zip(zip(target, y), y_predict):\n",
    "        print('{0:35} => {1:15} => {2:15}'.format(plat[0], plat[1], category))\n",
    "    \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "def gridsearchwithprecandrecall(model, X_train, y_train, X_test, y_test, tuned_parameters):\n",
    "    # Set the parameters by cross-validation\n",
    "    tuned_parameters = [tuned_parameters]\n",
    "    scores = ['precision', 'recall']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(model, tuned_parameters, cv=2,\n",
    "                           scoring='%s_macro' % score)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_predsearch = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_predsearch))\n",
    "        print()\n",
    "        return clf\n",
    "\n",
    "    \n",
    "def err(clf_stump, clf_err, X_test, y_test, params={}):\n",
    "    if params != {}:\n",
    "        clf_err.set_params(**params)\n",
    "    clf_stump_err = 1.0 - clf_stump.score(X_test, y_test)\n",
    "    clf_err = 1.0 - clf_err.score(X_test, y_test)\n",
    "    print('stump error : {0:.2f}; model error : {1:.2f}'.format(clf_stump_err, clf_err))\n",
    "    return clf_stump_err, clf_err\n",
    "\n",
    "\n",
    "\n",
    "#IMPORTANT... https://stackoverflow.com/questions/33110973/pass-a-dict-to-scikit-learn-estimator\n",
    "#clf_dtm_r2.set_params(**clf.best_params_)\n",
    "#clf_dt_r2 = clf_dtm_r2.fit(X_primercounts2, train2.category)\n",
    "\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "def ADA(model, stump_err, mod_err, X_train, y_train, X_test, y_test, n_estimators = 40, learning_rate = 1.):\n",
    "    ada_discrete = AdaBoostClassifier(\n",
    "        base_estimator = model,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        algorithm=\"SAMME\")\n",
    "    ada_discrete.fit(X_train, y_train)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.plot([1, n_estimators], [stump_err] * 2, 'k-',\n",
    "            label='Decision Stump Error')\n",
    "    ax.plot([1, n_estimators], [mod_err] * 2, 'k--',\n",
    "            label='Decision Tree Error')\n",
    "\n",
    "    ada_discrete_err = numpy.zeros((n_estimators,))\n",
    "    for i, y_pred in enumerate(ada_discrete.staged_predict(X_test)):\n",
    "        ada_discrete_err[i] = zero_one_loss(y_pred, y_test)\n",
    "\n",
    "    ada_discrete_err_train = numpy.zeros((n_estimators,))\n",
    "    for i, y_pred in enumerate(ada_discrete.staged_predict(X_train)):\n",
    "        ada_discrete_err_train[i] = zero_one_loss(y_pred, y_train)\n",
    "\n",
    "    ax.plot(numpy.arange(n_estimators) + 1, ada_discrete_err,\n",
    "            label='Discrete AdaBoost Test Error',\n",
    "            color='red')\n",
    "    ax.plot(numpy.arange(n_estimators) + 1, ada_discrete_err_train,\n",
    "            label='Discrete AdaBoost Train Error',\n",
    "            color='blue')\n",
    "\n",
    "    ax.set_ylim((0.0, 1.0))\n",
    "    ax.set_xlabel('n_estimators')\n",
    "    ax.set_ylabel('error rate')\n",
    "\n",
    "    leg = ax.legend(loc='upper right', fancybox=True)\n",
    "    leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "    plt.show()\n",
    "    return ada_discrete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train3=pd_annotated[['platform', 'alltext', 'jscheck', 'docscheck', 'blogscheck', 'commcheck', 'category']].sample(frac=0.75)\n",
    "test3=pd_annotated[['platform', 'alltext','jscheck', 'docscheck', 'blogscheck', 'commcheck', 'category']].drop(train3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>alltext</th>\n",
       "      <th>jscheck</th>\n",
       "      <th>docscheck</th>\n",
       "      <th>blogscheck</th>\n",
       "      <th>commcheck</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>docs.webplatform.org</td>\n",
       "      <td>welcome summary community aims docs source d...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DOCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>www.facebook.com</td>\n",
       "      <td>je een en om end video te die activeer josep...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>COMMUITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>dl.dropboxusercontent.com</td>\n",
       "      <td>error timer link u dropbox file q8zgw lkj2de...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NOCLASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>openweathermap.org</td>\n",
       "      <td>wind charts world faq urrent img help images...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PACKAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>blog.engineyard.com</td>\n",
       "      <td>engine advantages blog service vpc yard anno...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>api.jqueryui.com</td>\n",
       "      <td>interested check new library widgets full ef...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PACKAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>jsonplaceholder.typicode.com</td>\n",
       "      <td>posts fake rest api server online testing po...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PACKAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>port-80-jico6278fu.treehouse-app.com</td>\n",
       "      <td>error encountered preview active quote works...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NOCLASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>j4n.co</td>\n",
       "      <td>end jan front system user ui interface blog ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>imperavi.com</td>\n",
       "      <td>charts minimalistic simple developers profes...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NEWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 platform  \\\n",
       "567                  docs.webplatform.org   \n",
       "771                      www.facebook.com   \n",
       "403             dl.dropboxusercontent.com   \n",
       "16                     openweathermap.org   \n",
       "151                   blog.engineyard.com   \n",
       "61                       api.jqueryui.com   \n",
       "74           jsonplaceholder.typicode.com   \n",
       "590  port-80-jico6278fu.treehouse-app.com   \n",
       "280                                j4n.co   \n",
       "177                          imperavi.com   \n",
       "\n",
       "                                               alltext  jscheck  docscheck  \\\n",
       "567    welcome summary community aims docs source d...        0          1   \n",
       "771    je een en om end video te die activeer josep...        0          0   \n",
       "403    error timer link u dropbox file q8zgw lkj2de...        0          0   \n",
       "16     wind charts world faq urrent img help images...        0          0   \n",
       "151    engine advantages blog service vpc yard anno...        0          0   \n",
       "61     interested check new library widgets full ef...        0          0   \n",
       "74     posts fake rest api server online testing po...        0          0   \n",
       "590    error encountered preview active quote works...        0          0   \n",
       "280    end jan front system user ui interface blog ...        0          0   \n",
       "177    charts minimalistic simple developers profes...        0          0   \n",
       "\n",
       "     blogscheck  commcheck  category  \n",
       "567           0          0      DOCS  \n",
       "771           0          0  COMMUITY  \n",
       "403           0          0   NOCLASS  \n",
       "16            0          0   PACKAGE  \n",
       "151           1          0      NEWS  \n",
       "61            0          0   PACKAGE  \n",
       "74            0          0   PACKAGE  \n",
       "590           0          0   NOCLASS  \n",
       "280           0          0      NEWS  \n",
       "177           0          0      NEWS  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>alltext</th>\n",
       "      <th>jscheck</th>\n",
       "      <th>docscheck</th>\n",
       "      <th>blogscheck</th>\n",
       "      <th>commcheck</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jscroll.com</td>\n",
       "      <td>plugin loaded github new com iscroll cubiq e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PACKAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>v4-alpha.getbootstrap.com)</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PACKAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>crossorigin.me</td>\n",
       "      <td>crossorigin org wind github master calculato...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PACKAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>flipclockjs.com</td>\n",
       "      <td>conditionals solutions stash enough many dom...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PACKAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>anyorigin.com</td>\n",
       "      <td>jsonp access go policy exterminator watch do...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PACKAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>www.clementinejs.com</td>\n",
       "      <td>point simplicity starting fcc full developer...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PACKAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>jquery.com</td>\n",
       "      <td>library minified also less gzipped jquery gu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PACKAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>maxcdn.bootstrapcdn.com</td>\n",
       "      <td>font theme awesome alpha min cssy js bootstr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PACKAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>angularjs.org</td>\n",
       "      <td>testability pure templates superheroic depen...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PACKAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>www.angular-meteor.com</td>\n",
       "      <td>completely synchronization mongodb apollo au...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PACKAGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      platform  \\\n",
       "1                  jscroll.com   \n",
       "5   v4-alpha.getbootstrap.com)   \n",
       "7               crossorigin.me   \n",
       "10             flipclockjs.com   \n",
       "12               anyorigin.com   \n",
       "22        www.clementinejs.com   \n",
       "30                  jquery.com   \n",
       "33     maxcdn.bootstrapcdn.com   \n",
       "45               angularjs.org   \n",
       "46      www.angular-meteor.com   \n",
       "\n",
       "                                              alltext  jscheck  docscheck  \\\n",
       "1     plugin loaded github new com iscroll cubiq e...        0          0   \n",
       "5                                                            0          0   \n",
       "7     crossorigin org wind github master calculato...        0          0   \n",
       "10    conditionals solutions stash enough many dom...        1          0   \n",
       "12    jsonp access go policy exterminator watch do...        0          0   \n",
       "22    point simplicity starting fcc full developer...        1          0   \n",
       "30    library minified also less gzipped jquery gu...        0          0   \n",
       "33    font theme awesome alpha min cssy js bootstr...        0          0   \n",
       "45    testability pure templates superheroic depen...        1          0   \n",
       "46    completely synchronization mongodb apollo au...        0          0   \n",
       "\n",
       "    blogscheck  commcheck category  \n",
       "1            0          0  PACKAGE  \n",
       "5            0          0  PACKAGE  \n",
       "7            0          0  PACKAGE  \n",
       "10           0          0  PACKAGE  \n",
       "12           0          0  PACKAGE  \n",
       "22           0          0  PACKAGE  \n",
       "30           0          0  PACKAGE  \n",
       "33           0          0  PACKAGE  \n",
       "45           0          0  PACKAGE  \n",
       "46           0          0  PACKAGE  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA MODELLING 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, countmod = vectorizer(train3.alltext)\n",
    "X_trainh = hstacker(X_train, train3[['jscheck', 'docscheck', 'blogscheck', 'commcheck']])\n",
    "y_train = train3.category\n",
    "X_test = countmod.transform(test3.alltext)\n",
    "X_testh = hstacker(X_test, test3[['jscheck', 'docscheck', 'blogscheck', 'commcheck']])\n",
    "y_test = test3.category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE WITH ADABOOST, CLASSIFICATION 3\n",
    "\n",
    "### References:\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "* http://scikit-learn.org/stable/modules/tree.html\n",
    "* https://en.wikipedia.org/wiki/AdaBoost\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "* http://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_hastie_10_2.html#sphx-glr-auto-examples-ensemble-plot-adaboost-hastie-10-2-py\n",
    "* https://stackoverflow.com/questions/32210569/using-gridsearchcv-with-adaboost-and-decisiontreeclassifier\n",
    "* http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_digits.html\n",
    "* http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\n",
    "\n",
    "**Also**:\n",
    "* https://stackoverflow.com/questions/33110973/pass-a-dict-to-scikit-learn-estimator\n",
    "* http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slump_params = {'max_depth':1, 'min_samples_leaf':1, 'random_state':0}\n",
    "mod_params = {'min_samples_leaf':2, 'random_state':0}\n",
    "\n",
    "clf_dt_slump, dt_fit_slump = modelling(DecisionTreeClassifier, X_train, y_train, slump_params)\n",
    "clf_dt_mod, dt_fit = DT(DecisionTreeClassifier, X_train, y_train, mod_params)\n",
    "\n",
    "clf_dt_slumph, dt_fit_slumph = DT(DecisionTreeClassifier, X_trainh, y_train, slump_params)\n",
    "clf_dt_modh, dt_fith = DT(DecisionTreeClassifier, X_trainh, y_train, mod_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Searching for the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = {'max_depth': numpy.arange(5,25,2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 19}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.164 (+/-0.030) for {'max_depth': 5}\n",
      "0.168 (+/-0.002) for {'max_depth': 7}\n",
      "0.204 (+/-0.077) for {'max_depth': 9}\n",
      "0.201 (+/-0.079) for {'max_depth': 11}\n",
      "0.223 (+/-0.081) for {'max_depth': 13}\n",
      "0.226 (+/-0.084) for {'max_depth': 15}\n",
      "0.225 (+/-0.084) for {'max_depth': 17}\n",
      "0.295 (+/-0.069) for {'max_depth': 19}\n",
      "0.245 (+/-0.032) for {'max_depth': 21}\n",
      "0.249 (+/-0.014) for {'max_depth': 23}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   BUSINESS       0.20      0.17      0.18         6\n",
      "   COMMUITY       0.00      0.00      0.00         2\n",
      "       DOCS       0.29      0.40      0.33         5\n",
      "  ECOMMERCE       0.00      0.00      0.00         2\n",
      "       NEWS       0.70      0.65      0.67        85\n",
      "    NOCLASS       0.11      0.09      0.10        11\n",
      "       PAAS       0.00      0.00      0.00         0\n",
      "    PACKAGE       0.45      0.63      0.53        41\n",
      "       REPL       0.00      0.00      0.00         4\n",
      "    SENGINE       0.00      0.00      0.00         1\n",
      "      THEME       0.00      0.00      0.00         8\n",
      "   TRAINING       0.54      0.46      0.50        28\n",
      "\n",
      "avg / total       0.50      0.51      0.50       193\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "gs_clf_dt_mod = gridsearchwithprecandrecall(clf_dt_mod, X_train, y_train, X_test, y_test, tuned_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 17}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.235 (+/-0.032) for {'max_depth': 5}\n",
      "0.253 (+/-0.010) for {'max_depth': 7}\n",
      "0.305 (+/-0.107) for {'max_depth': 9}\n",
      "0.284 (+/-0.034) for {'max_depth': 11}\n",
      "0.313 (+/-0.033) for {'max_depth': 13}\n",
      "0.296 (+/-0.068) for {'max_depth': 15}\n",
      "0.321 (+/-0.027) for {'max_depth': 17}\n",
      "0.250 (+/-0.108) for {'max_depth': 19}\n",
      "0.262 (+/-0.108) for {'max_depth': 21}\n",
      "0.266 (+/-0.140) for {'max_depth': 23}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   BUSINESS       0.20      0.17      0.18         6\n",
      "   COMMUITY       0.00      0.00      0.00         2\n",
      "       DOCS       0.00      0.00      0.00         5\n",
      "  ECOMMERCE       0.00      0.00      0.00         2\n",
      "       NEWS       0.70      0.65      0.67        85\n",
      "    NOCLASS       0.00      0.00      0.00        11\n",
      "       PAAS       0.00      0.00      0.00         0\n",
      "    PACKAGE       0.40      0.73      0.52        41\n",
      "       REPL       0.25      0.25      0.25         4\n",
      "    SENGINE       0.00      0.00      0.00         1\n",
      "      THEME       0.33      0.12      0.18         8\n",
      "   TRAINING       0.60      0.43      0.50        28\n",
      "\n",
      "avg / total       0.50      0.52      0.50       193\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ec/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "gs_clf_dt_modh = gridsearchwithprecandrecall(clf_dt_modh, X_trainh, y_train, X_testh, y_test, tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###a different parameter to be adjusted? use gs_clf!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'err' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2b654bb81b17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf_dt_stump_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_dt_mod_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_dt_slump\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_dt_mod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgs_clf_dt_mod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclf_dt_stump_errh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_dt_mod_errh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_dt_slumph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_dt_modh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_testh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgs_clf_dt_modh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'err' is not defined"
     ]
    }
   ],
   "source": [
    "clf_dt_stump_err, clf_dt_mod_err = err(clf_dt_slump, clf_dt_mod, X_test, y_test, gs_clf_dt_mod.best_params_)\n",
    "clf_dt_stump_errh, clf_dt_mod_errh = err(clf_dt_slumph, clf_dt_modh, X_testh, y_test, gs_clf_dt_modh.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_adadt_mod = ADA(clf_dt_mod, clf_dt_stump_err, clf_dt_mod_err, X_train, y_train, X_test, y_test, n_estimators = 40, learning_rate = .5)\n",
    "clf_adadt_modh = ADA(clf_dt_modh, clf_dt_stump_errh, clf_dt_mod_errh, X_trainh, y_train, X_testh, y_test, n_estimators = 40, learning_rate = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "STOP HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST WITH ADABOOST, CLASSIFICATION 3\n",
    "\n",
    "### References:\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "* http://scikit-learn.org/stable/modules/tree.html\n",
    "* https://en.wikipedia.org/wiki/AdaBoost\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "* http://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_hastie_10_2.html#sphx-glr-auto-examples-ensemble-plot-adaboost-hastie-10-2-py\n",
    "* https://stackoverflow.com/questions/32210569/using-gridsearchcv-with-adaboost-and-decisiontreeclassifier\n",
    "* http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_digits.html\n",
    "* http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\n",
    "\n",
    "**Also**:\n",
    "* https://stackoverflow.com/questions/33110973/pass-a-dict-to-scikit-learn-estimator\n",
    "* http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slump_params = {'max_depth':1, 'min_samples_leaf':1, 'random_state':0}\n",
    "mod_params = {'min_samples_leaf':2, 'random_state':0}\n",
    "\n",
    "\n",
    "clf_rf_slump, rf_fit_slump = modelling(RandomForestClassifier, X_train, y_train, slump_params)\n",
    "clf_rf_mod, rf_fit = DT(RandomForestClassifier, X_train, y_train, mod_params)\n",
    "\n",
    "clf_rf_slumph, rf_fit_slumph = DT(RandomForestClassifier, X_trainh, y_train, slump_params)\n",
    "clf_rf_modh, rf_fith = DT(RandomForestClassifier, X_trainh, y_train, mod_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Searching for the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = {'max_depth': numpy.arange(5,25,2), 'n_estimators': numpy.arrange(5,30,5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_clf_rf_mod = gridsearchwithprecandrecall(clf_rf_mod, X_train, y_train, X_test, y_test, tuned_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs_clf_rf_modh = gridsearchwithprecandrecall(clf_rf_modh, X_trainh, y_train, X_testh, y_test, tuned_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###a different parameter to be adjusted? use gs_clf!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_rf_stump_err, clf_rf_mod_err = err(clf_rf_slump, clf_rf_mod, X_test, y_test, gs_clf_rf_mod.best_params_)\n",
    "clf_rf_stump_errh, clf_rf_mod_errh = err(clf_rf_slumph, clf_rf_modh, X_testh, y_test, gs_clf_rf_modh.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_adarf_mod = ADA(clf_rf_mod, clf_rf_stump_err, clf_rf_mod_err, X_train, y_train, X_test, y_test, n_estimators = 40, learning_rate = .5)\n",
    "clf_adarf_modh = ADA(clf_rf_modh, clf_rf_stump_errh, clf_rf_mod_errh, X_trainh, y_train, X_testh, y_test, n_estimators = 40, learning_rate = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "STOP HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "STOP HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "STOP HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA MODELLING - VECTOR MODEL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect_r3 = CountVectorizer(ngram_range=(1,2))\n",
    "X_primercounts3 = count_vect_r3.fit_transform(train3.alltext)\n",
    "X_primercounts3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(X_primercounts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "import copy\n",
    "X_primercounts3h = hstack((copy.copy(X_primercounts3), train3[['jscheck', 'docscheck', 'blogscheck', 'commcheck']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_primercounts3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_primercounts3h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE WITH ADABOOST, CLASSIFICATION 3\n",
    "\n",
    "### References:\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "* http://scikit-learn.org/stable/modules/tree.html\n",
    "* https://en.wikipedia.org/wiki/AdaBoost\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "* http://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_hastie_10_2.html#sphx-glr-auto-examples-ensemble-plot-adaboost-hastie-10-2-py\n",
    "* https://stackoverflow.com/questions/32210569/using-gridsearchcv-with-adaboost-and-decisiontreeclassifier\n",
    "* http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_digits.html\n",
    "* http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\n",
    "\n",
    "**Also**:\n",
    "* https://stackoverflow.com/questions/33110973/pass-a-dict-to-scikit-learn-estimator\n",
    "* http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_dtm_r3_stump = DecisionTreeClassifier(max_depth=1, min_samples_leaf=1, random_state=0)\n",
    "clf_dtm_r3 = DecisionTreeClassifier(min_samples_leaf=2, random_state=0)\n",
    "\n",
    "clf_dt_r3_stump = clf_dtm_r3_stump.fit(X_primercounts3, train3.category)\n",
    "clf_dt_r3 = clf_dtm_r3.fit(X_primercounts3, train3.category)\n",
    "\n",
    "\n",
    "clf_dtm_r3_stumph = DecisionTreeClassifier(max_depth=1, min_samples_leaf=1, random_state=0)\n",
    "clf_dtm_r3h = DecisionTreeClassifier(min_samples_leaf=2, random_state=0)\n",
    "\n",
    "clf_dt_r3_stumph = clf_dtm_r3_stumph.fit(X_primercounts3h, train3.category)\n",
    "clf_dt_r3h = clf_dtm_r3h.fit(X_primercounts3h, train3.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of the Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test3counts_stump = count_vect_r3.transform(test3.alltext)\n",
    "predicted_dt_r3_stump = clf_dt_r3_stump.predict(X_test3counts_stump)\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "X_test3counts_stumph = hstack((X_test3counts_stump, test3[['jscheck', 'docscheck', 'blogscheck', 'commcheck']]))\n",
    "predicted_dt_r3_stumph = clf_dt_r3_stumph.predict(X_test3counts_stumph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for platform, category in zip(test.platform, predicted_dt_r1_stump):\n",
    "#    print('%r => %s' % (platform, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test3counts = count_vect_r3.transform(test3.alltext)\n",
    "predicted_dt_r3 = clf_dt_r3.predict(X_test3counts)\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "X_test3countsh = hstack((X_test3counts, test3[['jscheck', 'docscheck', 'blogscheck', 'commcheck']]))\n",
    "predicted_dt_r3h = clf_dt_r3h.predict(X_test3countsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for plat, category in zip(zip(test3.platform,test3.category), predicted_dt_r3):\n",
    "    print('%r => %s => %s' % (plat[0], plat[1], category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Searching for the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'max_depth': numpy.arange(5,25,2)}]\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(clf_dtm_r3, tuned_parameters, cv=2,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_primercounts3, train3.category)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_predsearch = test3.category, clf.predict(X_test3counts)\n",
    "    print(classification_report(y_true, y_predsearch))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'max_depth': numpy.arange(5,25,2)}]\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(clf_dtm_r3h, tuned_parameters, cv=2,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_primercounts3h, train3.category)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_predsearch = test3.category, clf.predict(X_test3countsh)\n",
    "    print(classification_report(y_true, y_predsearch))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_test3counts_stump = count_vect_r3.transform(test3.alltext)\n",
    "\n",
    "#from scipy.sparse import csr_matrix, hstack\n",
    "#X_test3counts_stump = hstack((X_test3counts_stump, test3[['jscheck', 'docscheck', 'blogscheck', 'commcheck']]))\n",
    "\n",
    "clf_dt_r3_stump_err = 1.0 - clf_dt_r3_stump.score(X_test3counts_stump, test3.category)\n",
    "\n",
    "#X_test3count = count_vect_r3.transform(test3.alltext)\n",
    "\n",
    "#from scipy.sparse import csr_matrix, hstack\n",
    "#X_test3counts = hstack((X_test3counts, test3[['jscheck', 'docscheck', 'blogscheck', 'commcheck']]))\n",
    "\n",
    "clf_dt_r3_err = 1.0 - clf.score(X_test3counts, test3.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(clf_dt_r3_stump_err,clf_dt_r3_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clf_dtm_r3 = DecisionTreeClassifier(min_samples_leaf=2, random_state=0)\n",
    "clf_dtm_r3.set_params(**{'max_depth': 13})\n",
    "clf_dt_r3 = clf_dtm_r3.fit(X_primercounts3, train3.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_dt_r3_err = 1.0 - clf_dt_r3.score(X_test3counts, test3.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(clf_dt_r3_stump_err,clf_dt_r3_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_estimators = 40\n",
    "# A learning rate of 1. may not be optimal for both SAMME and SAMME.R\n",
    "learning_rate = .2\n",
    "\n",
    "\n",
    "#IMPORTANT... https://stackoverflow.com/questions/33110973/pass-a-dict-to-scikit-learn-estimator\n",
    "#clf_dtm_r2.set_params(**clf.best_params_)\n",
    "#clf_dt_r2 = clf_dtm_r2.fit(X_primercounts2, train2.category)\n",
    "\n",
    "ada_discrete = AdaBoostClassifier(\n",
    "    base_estimator = clf_dt_r3,\n",
    "    learning_rate=learning_rate,\n",
    "    n_estimators=n_estimators,\n",
    "    algorithm=\"SAMME\")\n",
    "ada_discrete.fit(X_primercounts3, train3.category)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot([1, n_estimators], [clf_rf_r3_stump_err] * 2, 'k-',\n",
    "        label='Decision Stump Error')\n",
    "ax.plot([1, n_estimators], [clf_rf_r3_err] * 2, 'k--',\n",
    "        label='Decision Tree Error')\n",
    "\n",
    "ada_discrete_err = numpy.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_discrete.staged_predict(X_test3counts)):\n",
    "    ada_discrete_err[i] = zero_one_loss(y_pred, test3.category)\n",
    "\n",
    "ada_discrete_err_train = numpy.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_discrete.staged_predict(X_primercounts3)):\n",
    "    ada_discrete_err_train[i] = zero_one_loss(y_pred, train3.category)\n",
    "\n",
    "ax.plot(numpy.arange(n_estimators) + 1, ada_discrete_err,\n",
    "        label='Discrete AdaBoost Test Error',\n",
    "        color='red')\n",
    "ax.plot(numpy.arange(n_estimators) + 1, ada_discrete_err_train,\n",
    "        label='Discrete AdaBoost Train Error',\n",
    "        color='blue')\n",
    "\n",
    "ax.set_ylim((0.0, 1.0))\n",
    "ax.set_xlabel('n_estimators')\n",
    "ax.set_ylabel('error rate')\n",
    "\n",
    "leg = ax.legend(loc='upper right', fancybox=True)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_ada_r3 = ada_discrete.predict(X_test3counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for *bcategory, category in zip(zip(zip(test3.platform,test3.category), best_categories), predicted_ada_r3):\n",
    "    plat = bcategory[0][0]\n",
    "    bcategory = bcategory[0][1]\n",
    "    print('%r => %s => %s => %s' % (plat[0], plat[1], bcategory.lower(), category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(test3.category, predicted_ada_r3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_estimators = 40\n",
    "# A learning rate of 1. may not be optimal for both SAMME and SAMME.R\n",
    "learning_rate = .2\n",
    "\n",
    "\n",
    "#IMPORTANT... https://stackoverflow.com/questions/33110973/pass-a-dict-to-scikit-learn-estimator\n",
    "#clf_dtm_r2.set_params(**clf.best_params_)\n",
    "#clf_dt_r2 = clf_dtm_r2.fit(X_primercounts2, train2.category)\n",
    "\n",
    "ada_discrete = AdaBoostClassifier(\n",
    "    base_estimator = clf_dt_r3h,\n",
    "    learning_rate=learning_rate,\n",
    "    n_estimators=n_estimators,\n",
    "    algorithm=\"SAMME\")\n",
    "ada_discrete.fit(X_primercounts3h, train3.category)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot([1, n_estimators], [clf_dt_r3_stump_err] * 2, 'k-',\n",
    "        label='Decision Stump Error')\n",
    "ax.plot([1, n_estimators], [clf_rf_r3_err] * 2, 'k--',\n",
    "        label='Decision Tree Error')\n",
    "\n",
    "ada_discrete_err = numpy.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_discrete.staged_predict(X_test3counts)):\n",
    "    ada_discrete_err[i] = zero_one_loss(y_pred, test3.category)\n",
    "\n",
    "ada_discrete_err_train = numpy.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_discrete.staged_predict(X_primercounts3)):\n",
    "    ada_discrete_err_train[i] = zero_one_loss(y_pred, train3.category)\n",
    "\n",
    "ax.plot(numpy.arange(n_estimators) + 1, ada_discrete_err,\n",
    "        label='Discrete AdaBoost Test Error',\n",
    "        color='red')\n",
    "ax.plot(numpy.arange(n_estimators) + 1, ada_discrete_err_train,\n",
    "        label='Discrete AdaBoost Train Error',\n",
    "        color='blue')\n",
    "\n",
    "ax.set_ylim((0.0, 1.0))\n",
    "ax.set_xlabel('n_estimators')\n",
    "ax.set_ylabel('error rate')\n",
    "\n",
    "leg = ax.legend(loc='upper right', fancybox=True)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_ada_r3 = ada_discrete.predict(X_test3counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for *bcategory, category in zip(zip(zip(test3.platform,test3.category), best_categories), predicted_ada_r3):\n",
    "    plat = bcategory[0][0]\n",
    "    bcategory = bcategory[0][1]\n",
    "    print('%r => %s => %s => %s' % (plat[0], plat[1], bcategory.lower(), category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(test3.category, predicted_ada_r3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "here stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST, CLASSIFICATION 2\n",
    "\n",
    "### References:\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "* http://scikit-learn.org/stable/modules/ensemble.html#forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import zero_one_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_estimators = 25\n",
    "# A learning rate of 1. may not be optimal for both SAMME and SAMME.R\n",
    "#learning_rate = 1.\n",
    "\n",
    "clf_rfm_r3_stump = RandomForestClassifier(max_depth=1, min_samples_leaf=1, n_estimators=n_estimators, random_state=0)\n",
    "clf_rf_r3_stump = clf_rfm_r3_stump.fit(X_primercounts3, train3.category)\n",
    "\n",
    "clf_rfm_r3 = RandomForestClassifier(max_depth=20, min_samples_leaf=2, n_estimators=n_estimators, random_state=0)\n",
    "clf_rf_r3 = clf_rfm_r3.fit(X_primercounts3, train3.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_test3counts_stump = count_vect_r3.transform(test3.alltext)\n",
    "predicted_rf_r3_stump = clf_rf_r3_stump.predict(X_test3counts_stump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for platform, category in zip(test2.platform, predicted_rf_r3_stump):\n",
    "    print('%r => %s' % (platform, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_test3counts = count_vect_r3.transform(test3.alltext)\n",
    "predicted_rf_r3 = clf_rf_r3.predict(X_test3counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for plat, category1, category2 in zip(zip(test3.platform,test3.category), predicted_rf_r3, predicted_dt_r3):\n",
    "    best_category = ''\n",
    "    print('%r => %s => %s => %s => %s' % (plat[0], plat[1].lower(), category1, category2, best_category.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_test2counts_stump = count_vect_r2.transform(test2.alltext)\n",
    "clf_rf_r3_stump_err = 1.0 - clf_rf_r3_stump.score(X_test3counts_stump, test3.category)\n",
    "#X_test2count = count_vect_r2.transform(test2.alltext)\n",
    "clf_rf_r3_err = 1.0 - clf_rf_r3.score(X_test3counts, test3.category)\n",
    "\n",
    "clf_rf_r3_bc_err = 1.0 - clf_rf_r3.score(X_test3counts, best_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(clf_rf_r3_stump_err,clf_rf_r3_err, clf_rf_r3_bc_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(test3.category, best_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(test3.category, predicted_rf_r3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_estimators = 40\n",
    "# A learning rate of 1. may not be optimal for both SAMME and SAMME.R\n",
    "learning_rate = .2\n",
    "\n",
    "\n",
    "#IMPORTANT... https://stackoverflow.com/questions/33110973/pass-a-dict-to-scikit-learn-estimator\n",
    "#clf_dtm_r2.set_params(**clf.best_params_)\n",
    "#clf_dt_r2 = clf_dtm_r2.fit(X_primercounts2, train2.category)\n",
    "\n",
    "ada_discrete = AdaBoostClassifier(\n",
    "    base_estimator = clf_rf_r3,\n",
    "    learning_rate=learning_rate,\n",
    "    n_estimators=n_estimators,\n",
    "    algorithm=\"SAMME\")\n",
    "ada_discrete.fit(X_primercounts3, train3.category)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot([1, n_estimators], [clf_rf_r3_stump_err] * 2, 'k-',\n",
    "        label='Decision Stump Error')\n",
    "ax.plot([1, n_estimators], [clf_rf_r3_err] * 2, 'k--',\n",
    "        label='Decision Tree Error')\n",
    "\n",
    "ada_discrete_err = numpy.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_discrete.staged_predict(X_test3counts)):\n",
    "    ada_discrete_err[i] = zero_one_loss(y_pred, test3.category)\n",
    "\n",
    "ada_discrete_err_train = numpy.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_discrete.staged_predict(X_primercounts3)):\n",
    "    ada_discrete_err_train[i] = zero_one_loss(y_pred, train3.category)\n",
    "\n",
    "ax.plot(numpy.arange(n_estimators) + 1, ada_discrete_err,\n",
    "        label='Discrete AdaBoost Test Error',\n",
    "        color='red')\n",
    "ax.plot(numpy.arange(n_estimators) + 1, ada_discrete_err_train,\n",
    "        label='Discrete AdaBoost Train Error',\n",
    "        color='blue')\n",
    "\n",
    "ax.set_ylim((0.0, 1.0))\n",
    "ax.set_xlabel('n_estimators')\n",
    "ax.set_ylabel('error rate')\n",
    "\n",
    "leg = ax.legend(loc='upper right', fancybox=True)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_ada_r3 = ada_discrete.predict(X_test3counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for *bcategory, category in zip(zip(zip(test3.platform,test3.category), best_categories), predicted_ada_r3):\n",
    "    plat = bcategory[0][0]\n",
    "    bcategory = bcategory[0][1]\n",
    "    print('%r => %s => %s => %s' % (plat[0], plat[1], bcategory.lower(), category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newbest_categories = []\n",
    "for *bcategory, category in zip(zip(zip(test3.platform,test3.category), best_categories), predicted_ada_r3):\n",
    "    plat = bcategory[0][0]\n",
    "    bcategory = bcategory[0][1]\n",
    "    if bcategory == 'TRAINING' and category != 'NOCLASS':\n",
    "        newbest_categories.append('TRAINING')\n",
    "    else:\n",
    "        newbest_categories.append(category)\n",
    "    \n",
    "    if category == 'REPL':\n",
    "        print('%r => %s => %s => %s' % (plat[0], plat[1], bcategory.lower(), category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(test3.category, predicted_ada_r3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(test3.category, newbest_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train3=pd_annotated2[['platform', 'alltext','category']].sample(frac=0.75,random_state=0)\n",
    "test3=pd_annotated2[['platform', 'alltext','category']].drop(train3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train3.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA MODELLING - VECTOR MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect_r2 = CountVectorizer(ngram_range=(1,2))\n",
    "X_primercounts2 = count_vect_r2.fit_transform(train2.alltext)\n",
    "X_primercounts2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE WITH ADABOOST, CLASSIFICATION 2\n",
    "\n",
    "### References:\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "* http://scikit-learn.org/stable/modules/tree.html\n",
    "* https://en.wikipedia.org/wiki/AdaBoost\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "* http://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_hastie_10_2.html#sphx-glr-auto-examples-ensemble-plot-adaboost-hastie-10-2-py\n",
    "* https://stackoverflow.com/questions/32210569/using-gridsearchcv-with-adaboost-and-decisiontreeclassifier\n",
    "* http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_digits.html\n",
    "* http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\n",
    "\n",
    "**Also**:\n",
    "* https://stackoverflow.com/questions/33110973/pass-a-dict-to-scikit-learn-estimator\n",
    "* http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_dtm_r2_stump = DecisionTreeClassifier(max_depth=1, min_samples_leaf=1, random_state=0)\n",
    "clf_dt_r2_stump = clf_dtm_r2_stump.fit(X_primercounts2, train2.category)\n",
    "\n",
    "clf_dtm_r2 = DecisionTreeClassifier(min_samples_leaf=2, random_state=0)\n",
    "clf_dt_r2 = clf_dtm_r2.fit(X_primercounts2, train2.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of the Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test2counts_stump = count_vect_r2.transform(test2.alltext)\n",
    "predicted_dt_r2_stump = clf_dt_r2_stump.predict(X_test2counts_stump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for platform, category in zip(test.platform, predicted_dt_r1_stump):\n",
    "#    print('%r => %s' % (platform, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test2counts = count_vect_r2.transform(test2.alltext)\n",
    "predicted_dt_r2 = clf_dt_r2.predict(X_test2counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for plat, category in zip(zip(test2.platform,test2.category), predicted_dt_r2):\n",
    "    print('%r => %s => %s' % (plat[0], plat[1], category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Searching for the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'max_depth': numpy.arange(5,25,2)}]\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(clf_dtm_r2, tuned_parameters, cv=2,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_primercounts2, train2.category)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_predsearch = test2.category, clf.predict(X_test2counts)\n",
    "    print(classification_report(y_true, y_predsearch))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test2counts_stump = count_vect_r2.transform(test2.alltext)\n",
    "clf_dt_r2_stump_err = 1.0 - clf_dt_r2_stump.score(X_test2counts_stump, test2.category)\n",
    "X_test2count = count_vect_r2.transform(test2.alltext)\n",
    "clf_dt_r2_err = 1.0 - clf.score(X_test2counts, test2.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(clf_dt_r2_stump_err,clf_dt_r2_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_estimators = 40\n",
    "# A learning rate of 1. may not be optimal for both SAMME and SAMME.R\n",
    "learning_rate = .5\n",
    "\n",
    "\n",
    "#IMPORTANT... https://stackoverflow.com/questions/33110973/pass-a-dict-to-scikit-learn-estimator\n",
    "clf_dtm_r2.set_params(**clf.best_params_)\n",
    "clf_dt_r2 = clf_dtm_r2.fit(X_primercounts2, train2.category)\n",
    "\n",
    "ada_discrete = AdaBoostClassifier(\n",
    "    base_estimator = clf_dtm_r2,\n",
    "    learning_rate=learning_rate,\n",
    "    n_estimators=n_estimators,\n",
    "    algorithm=\"SAMME\")\n",
    "ada_discrete.fit(X_primercounts2, train2.category)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot([1, n_estimators], [clf_dt_r2_stump_err] * 2, 'k-',\n",
    "        label='Decision Stump Error')\n",
    "ax.plot([1, n_estimators], [clf_dt_r2_err] * 2, 'k--',\n",
    "        label='Decision Tree Error')\n",
    "\n",
    "ada_discrete_err = numpy.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_discrete.staged_predict(X_test2counts)):\n",
    "    ada_discrete_err[i] = zero_one_loss(y_pred, test2.category)\n",
    "\n",
    "ada_discrete_err_train = numpy.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_discrete.staged_predict(X_primercounts2)):\n",
    "    ada_discrete_err_train[i] = zero_one_loss(y_pred, train2.category)\n",
    "\n",
    "ax.plot(numpy.arange(n_estimators) + 1, ada_discrete_err,\n",
    "        label='Discrete AdaBoost Test Error',\n",
    "        color='red')\n",
    "ax.plot(numpy.arange(n_estimators) + 1, ada_discrete_err_train,\n",
    "        label='Discrete AdaBoost Train Error',\n",
    "        color='blue')\n",
    "\n",
    "ax.set_ylim((0.0, 1.0))\n",
    "ax.set_xlabel('n_estimators')\n",
    "ax.set_ylabel('error rate')\n",
    "\n",
    "leg = ax.legend(loc='upper right', fancybox=True)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Stop HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.getcwd()+'/data/adaboostmodel1.pkl', 'bw') as mod:\n",
    "    pickle.dump([train, test, train.alltext, train.category, count_vect_r1, X_primercounts, clf_dtm_r1, clf_dt_r1, ada_discrete, n_estimators, learning_rate], mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying unlabelled records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_unclass1counts = count_vect_r1.transform(pd_notated.alltext)\n",
    "#normalized_X_testround1_counts = sklearn.feature_extraction.text.TfidfTransformer(norm='l2').fit_transform(X_testround1_counts)\n",
    "predicted_dtada_r1 = ada_discrete.predict(X_unclass1counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for platform, category in zip(pd_notated.platform, predicted_dtada_r1):\n",
    "    print('%r => %s' % (platform, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.getcwd()+'/data/abadt_1.csv', 'w') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=';', quotechar=\"'\")\n",
    "    writer.writerow(['platform','assignedcategory','checked','category'])\n",
    "    for platform, category in zip(pd_notated.platform, predicted_dtada_r1):\n",
    "        #print('%r => %s' % (platform, category))\n",
    "        writer.writerow([platform,category,,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "here stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUMPED!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST, CLASSIFICATION 1\n",
    "\n",
    "### References:\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "* http://scikit-learn.org/stable/modules/ensemble.html#forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import zero_one_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n_estimators = 25\n",
    "# A learning rate of 1. may not be optimal for both SAMME and SAMME.R\n",
    "#learning_rate = 1.\n",
    "\n",
    "clf_rfm_r2_stump = RandomForestClassifier(max_depth=1, min_samples_leaf=1, n_estimators=n_estimators, random_state=0)\n",
    "clf_rf_r2_stump = clf_rfm_r2_stump.fit(X_primercounts2, train2.category)\n",
    "\n",
    "clf_rfm_r2 = RandomForestClassifier(max_depth=20, min_samples_leaf=2, n_estimators=n_estimators, random_state=0)\n",
    "clf_rf_r2 = clf_rfm_r2.fit(X_primercounts2, train2.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_test1counts_stump = count_vect_r2.transform(test.alltext)\n",
    "predicted_rf_r2_stump = clf_rf_r2_stump.predict(X_test2counts_stump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for platform, category in zip(test2.platform, predicted_rf_r2_stump):\n",
    "    print('%r => %s' % (platform, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_test2counts = count_vect_r2.transform(test2.alltext)\n",
    "predicted_rf_r2 = clf_rf_r2.predict(X_test2counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_categories = []\n",
    "for plat, category1, category2 in zip(zip(test2.platform,test2.category), predicted_rf_r2, predicted_dt_r2):\n",
    "    best_category = ''\n",
    "    if category1 == category2:\n",
    "        best_category = category1\n",
    "    else:\n",
    "        if category1 == 'NEWS' and category2 == 'TRAINING':\n",
    "            best_category = category1\n",
    "\n",
    "        else:\n",
    "            best_category = category2\n",
    "    \n",
    "    if category1 != category2 and len(plat[0].split('.')) > 1:\n",
    "        if category2 in ['NOCLASS', 'BUSINESS', 'DOCS', 'PAAS', 'NEWS']:\n",
    "            #print(plat[0])\n",
    "            if len(plat[0].split('.')[-2]) > 2:\n",
    "                #print(plat[0].split('.')[-2])\n",
    "                if plat[0].split('.')[-2][-2:] == 'js':\n",
    "                    #print(len(plat[0].split('.')))\n",
    "                    #print(plat[0].split('.')[-2])\n",
    "                    best_category = 'PACKAGE'\n",
    "    \n",
    "    best_categories.append(best_category)\n",
    "    print('%r => %s => %s => %s => %s' % (plat[0], plat[1].lower(), category1, category2, best_category.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_test2counts_stump = count_vect_r2.transform(test2.alltext)\n",
    "clf_rf_r2_stump_err = 1.0 - clf_rf_r2_stump.score(X_test2counts_stump, test2.category)\n",
    "#X_test2count = count_vect_r2.transform(test2.alltext)\n",
    "clf_rf_r2_err = 1.0 - clf_rf_r2.score(X_test2counts, test2.category)\n",
    "\n",
    "clf_rf_r2_bc_err = 1.0 - clf_rf_r2.score(X_test2counts, best_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(clf_rf_r2_stump_err,clf_rf_r2_err, clf_rf_r2_bc_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(test2.category, best_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_estimators = 40\n",
    "# A learning rate of 1. may not be optimal for both SAMME and SAMME.R\n",
    "learning_rate = .2\n",
    "\n",
    "\n",
    "#IMPORTANT... https://stackoverflow.com/questions/33110973/pass-a-dict-to-scikit-learn-estimator\n",
    "#clf_dtm_r2.set_params(**clf.best_params_)\n",
    "#clf_dt_r2 = clf_dtm_r2.fit(X_primercounts2, train2.category)\n",
    "\n",
    "ada_discrete = AdaBoostClassifier(\n",
    "    base_estimator = clf_rf_r2,\n",
    "    learning_rate=learning_rate,\n",
    "    n_estimators=n_estimators,\n",
    "    algorithm=\"SAMME\")\n",
    "ada_discrete.fit(X_primercounts2, train2.category)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot([1, n_estimators], [clf_rf_r2_stump_err] * 2, 'k-',\n",
    "        label='Decision Stump Error')\n",
    "ax.plot([1, n_estimators], [clf_rf_r2_err] * 2, 'k--',\n",
    "        label='Decision Tree Error')\n",
    "\n",
    "ada_discrete_err = numpy.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_discrete.staged_predict(X_test2counts)):\n",
    "    ada_discrete_err[i] = zero_one_loss(y_pred, test2.category)\n",
    "\n",
    "ada_discrete_err_train = numpy.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_discrete.staged_predict(X_primercounts2)):\n",
    "    ada_discrete_err_train[i] = zero_one_loss(y_pred, train2.category)\n",
    "\n",
    "ax.plot(numpy.arange(n_estimators) + 1, ada_discrete_err,\n",
    "        label='Discrete AdaBoost Test Error',\n",
    "        color='red')\n",
    "ax.plot(numpy.arange(n_estimators) + 1, ada_discrete_err_train,\n",
    "        label='Discrete AdaBoost Train Error',\n",
    "        color='blue')\n",
    "\n",
    "ax.set_ylim((0.0, 1.0))\n",
    "ax.set_xlabel('n_estimators')\n",
    "ax.set_ylabel('error rate')\n",
    "\n",
    "leg = ax.legend(loc='upper right', fancybox=True)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_ada_r2 = ada_discrete.predict(X_test2counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newbest_categories = []\n",
    "for *bcategory, category in zip(zip(zip(test2.platform,test2.category), best_categories), predicted_ada_r2):\n",
    "    plat = bcategory[0][0]\n",
    "    bcategory = bcategory[0][1]\n",
    "    if bcategory == 'TRAINING' and category != 'NOCLASS':\n",
    "        newbest_categories.append('TRAINING')\n",
    "    else:\n",
    "        newbest_categories.append(category)\n",
    "    \n",
    "    if category == 'REPL':\n",
    "        print('%r => %s => %s => %s' % (plat[0], plat[1], bcategory.lower(), category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(test2.category, predicted_ada_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(test2.category, newbest_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS ROUND 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "* http://scikit-learn.org/stable/modules/cross_validation.html\n",
    "* https://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#xtrain, xtest, ytrain, ytest = train_test_split(pd_annotated.alltext, pd_annotated.category, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=pd_annotated[['platform', 'alltext','category']].sample(frac=0.75,random_state=0)\n",
    "test=pd_annotated[['platform', 'alltext','category']].drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA MODELLING - VECTOR MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect_r1 = CountVectorizer(ngram_range=(1,2))\n",
    "X_primercounts = count_vect_r1.fit_transform(train.alltext)\n",
    "X_primercounts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE WITH ADABOOST, CLASSIFICATION 1\n",
    "\n",
    "### References:\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "* http://scikit-learn.org/stable/modules/tree.html\n",
    "* https://en.wikipedia.org/wiki/AdaBoost\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "* http://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_hastie_10_2.html#sphx-glr-auto-examples-ensemble-plot-adaboost-hastie-10-2-py\n",
    "* https://stackoverflow.com/questions/32210569/using-gridsearchcv-with-adaboost-and-decisiontreeclassifier\n",
    "* http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_digits.html\n",
    "* http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\n",
    "\n",
    "**Also**:\n",
    "* https://stackoverflow.com/questions/33110973/pass-a-dict-to-scikit-learn-estimator\n",
    "* http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_dtm_r1_stump = DecisionTreeClassifier(max_depth=1, min_samples_leaf=1, random_state=0)\n",
    "clf_dt_r1_stump = clf_dtm_r1_stump.fit(X_primercounts, train.category)\n",
    "\n",
    "clf_dtm_r1 = DecisionTreeClassifier(min_samples_leaf=2, random_state=0)\n",
    "clf_dt_r1 = clf_dtm_r1.fit(X_primercounts, train.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of the Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test1counts_stump = count_vect_r1.transform(test.alltext)\n",
    "predicted_dt_r1_stump = clf_dt_r1_stump.predict(X_test1counts_stump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for platform, category in zip(test.platform, predicted_dt_r1_stump):\n",
    "#    print('%r => %s' % (platform, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test1counts = count_vect_r1.transform(test.alltext)\n",
    "predicted_dt_r1 = clf_dt_r1.predict(X_test1counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for platform, category in zip(test.platform, predicted_dt_r1):\n",
    "#    print('%r => %s' % (platform, category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Searching for the Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'max_depth': numpy.arange(5,25,5)}]\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(clf_dtm_r1, tuned_parameters, cv=2,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_primercounts, train.category)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_predsearch = test.category, clf.predict(X_test1counts)\n",
    "    print(classification_report(y_true, y_predsearch))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test1counts_stump = count_vect_r1.transform(test.alltext)\n",
    "clf_dt_r1_stump_err = 1.0 - clf_dt_r1_stump.score(X_test1counts_stump, test.category)\n",
    "X_test1count = count_vect_r1.transform(test.alltext)\n",
    "clf_err = 1.0 - clf.score(X_test1counts, test.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(clf_dt_r1_stump_err,clf_dt_r1_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_estimators = 40\n",
    "# A learning rate of 1. may not be optimal for both SAMME and SAMME.R\n",
    "learning_rate = 1.\n",
    "\n",
    "\n",
    "#IMPORTANT... https://stackoverflow.com/questions/33110973/pass-a-dict-to-scikit-learn-estimator\n",
    "clf_dtm_r1.set_params(**clf.best_params_)\n",
    "clf_dt_r1 = clf_dtm_r1.fit(X_primercounts, train.category)\n",
    "\n",
    "ada_discrete = AdaBoostClassifier(\n",
    "    base_estimator = clf_dtm_r1,\n",
    "    learning_rate=learning_rate,\n",
    "    n_estimators=n_estimators,\n",
    "    algorithm=\"SAMME\")\n",
    "ada_discrete.fit(X_primercounts, train.category)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot([1, n_estimators], [clf_dt_r1_stump_err] * 2, 'k-',\n",
    "        label='Decision Stump Error')\n",
    "ax.plot([1, n_estimators], [clf_dt_r1_err] * 2, 'k--',\n",
    "        label='Decision Tree Error')\n",
    "\n",
    "ada_discrete_err = numpy.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_discrete.staged_predict(X_test1counts)):\n",
    "    ada_discrete_err[i] = zero_one_loss(y_pred, test.category)\n",
    "\n",
    "ada_discrete_err_train = numpy.zeros((n_estimators,))\n",
    "for i, y_pred in enumerate(ada_discrete.staged_predict(X_primercounts)):\n",
    "    ada_discrete_err_train[i] = zero_one_loss(y_pred, train.category)\n",
    "\n",
    "ax.plot(numpy.arange(n_estimators) + 1, ada_discrete_err,\n",
    "        label='Discrete AdaBoost Test Error',\n",
    "        color='red')\n",
    "ax.plot(numpy.arange(n_estimators) + 1, ada_discrete_err_train,\n",
    "        label='Discrete AdaBoost Train Error',\n",
    "        color='blue')\n",
    "\n",
    "ax.set_ylim((0.0, 1.0))\n",
    "ax.set_xlabel('n_estimators')\n",
    "ax.set_ylabel('error rate')\n",
    "\n",
    "leg = ax.legend(loc='upper right', fancybox=True)\n",
    "leg.get_frame().set_alpha(0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.getcwd()+'/data/adaboostmodel1.pkl', 'bw') as mod:\n",
    "    pickle.dump([train, test, train.alltext, train.category, count_vect_r1, X_primercounts, clf_dtm_r1, clf_dt_r1, ada_discrete, n_estimators, learning_rate], mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying unlabelled records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_unclass1counts = count_vect_r1.transform(pd_notated.alltext)\n",
    "#normalized_X_testround1_counts = sklearn.feature_extraction.text.TfidfTransformer(norm='l2').fit_transform(X_testround1_counts)\n",
    "predicted_dtada_r1 = ada_discrete.predict(X_unclass1counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for platform, category in zip(pd_notated.platform, predicted_dtada_r1):\n",
    "    print('%r => %s' % (platform, category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.getcwd()+'/data/abadt_1.csv', 'w') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=';', quotechar=\"'\")\n",
    "    writer.writerow(['platform','assignedcategory','checked','category'])\n",
    "    for platform, category in zip(pd_notated.platform, predicted_dtada_r1):\n",
    "        #print('%r => %s' % (platform, category))\n",
    "        writer.writerow([platform,category,,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STOP HERE!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POST-ANALYSIS ROUND 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation after the manual supervision of the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.getcwd()+'/data/adaboostmodel1.pkl', 'br') as mod:\n",
    "    train, test, train.alltext, train.category, count_vect_r1, X_primercounts, clf_dtm_r1, clf_dt_r1, ada_discrete, n_estimators, learning_rate = pickle.load(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_unclass1counts = count_vect_r1.transform(pd_notated.alltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_notatedready_r1 = pandas.read_csv(open(os.getcwd()+'/data/abadt_1.csv', 'r'), sep=';', quotechar=\"'\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_notatedready_r1.loc[pd_notatedready_r1['checked'] != -1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd_notatedready_r1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(pd_notatedready_r1.loc[pd_notatedready_r1['checked'] != -1, 'category'], pd_notatedready_r1.loc[pd_notatedready_r1['checked'] != -1, 'assignedcategory']))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
